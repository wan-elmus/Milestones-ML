# -*- coding: utf-8 -*-
"""Milestone2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W5zHpXHfLnxE2GavpJ2IDjkUPTNXaYf-

# CIS 700 - Using the Long-Short Term Memory RNN for Sequence Classification of Industrial Control System Sensor Data (Milestone 2)



The following report explains how I applied LSTMs for sequence classification of industrial control system data for Milestone 2 . CUDA was used to improve the speed of training, however, I have commented blocks of code that allow for training without CUDA.

<h3>Section 0 - Load Libraries, Load Data</h3>
"""

# https://medium.com/@exesse/cuda-10-1-installation-on-ubuntu-18-04-lts-d04f89287130
# Install tensorflow-gpu
import pandas as pd
import numpy as np
import seaborn as sns
sns.set(color_codes=True)
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif, chi2
import tensorflow as tf
tf.logging.set_verbosity(tf.logging.ERROR)
from tensorflow.keras.layers import Activation, Input, Dropout, Layer, Dense, CuDNNLSTM, TimeDistributed, RepeatVector, LSTM
from tensorflow.keras.models import Model
from tensorflow.keras import regularizers
from tensorflow.keras import Sequential
from tensorflow.keras.optimizers import SGD
import warnings
warnings.filterwarnings("ignore")
pd.set_option('display.max_rows', 10)

dataset_abnorm1 = pd.read_csv('data/abnormal_20191029T110000_to_20191101T200000.csv')
dataset_abnorm2 = pd.read_csv('data/abnormal_20191104T150000_to_20191105T093000.csv')
dataset_norm1 = pd.read_csv('data/normal_20190911T200000_to_20190915T100000.csv')
dataset_norm2 = pd.read_csv('data/normal_20191101T200000_to_20191104T150000.csv')
dataset_norm1.dataframeName = 'normal_20191101T200000_to_20191104T150000.csv'

dataset_abnorm1['time'] = dataset_abnorm1['time'].astype(str).str[:-6].astype(np.str)
dataset_abnorm2['time'] = dataset_abnorm2['time'].astype(str).str[:-6].astype(np.str)
dataset_norm1["time"] = dataset_norm1['time'].astype(str).str[:-6].astype(np.str)
dataset_norm2["time"] = dataset_norm2['time'].astype(str).str[:-6].astype(np.str)

dataset_abnorm1['time'] = pd.to_datetime(dataset_abnorm1['time'])
dataset_abnorm2['time'] = pd.to_datetime(dataset_abnorm2['time'])
dataset_norm1["time"] = pd.to_datetime(dataset_norm1['time'])
dataset_norm2["time"] = pd.to_datetime(dataset_norm2['time'])

"""<h3>Section 1 - Previous/Related Contributions</h3>

As most of the selected projects use public datasets, no doubt there are different
attempts/projects to analyze those datasets. 30% of this deliverable is in your overall assessment
of previous data analysis efforts. This effort should include:

* Evaluating existing source codes that they have (e.g. in Kernels and discussion sections) or any other refence. Make sure you try those codes and show their results

<b>I did not see any other kernels or discussion besides the starter code. The code block below comes from the starter kernel on Kaggle. The code just shows a column distribution and correlation matrix of the normal_20191101T200000_to_20191104T150000.csv file.</b>
"""

# Distribution graphs (histogram/bar graph) of column data
def plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):
    nunique = df.nunique()
    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values
    nRow, nCol = df.shape
    columnNames = list(df)
    nGraphRow = (nCol + nGraphPerRow - 1) / nGraphPerRow
    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')
    for i in range(min(nCol, nGraphShown)):
        plt.subplot(nGraphRow, nGraphPerRow, i + 1)
        columnDf = df.iloc[:, i]
        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):
            valueCounts = columnDf.value_counts()
            valueCounts.plot.bar()
        else:
            columnDf.hist()
        plt.ylabel('counts')
        plt.xticks(rotation = 90)
        plt.title('{} (column {})'.format(columnNames[i], i))
    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)
    plt.show()

# Correlation matrix
def plotCorrelationMatrix(df, graphWidth):
    filename = df.dataframeName
    df = df.dropna('columns') # drop columns with NaN
    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values
    if df.shape[1] < 2:
        print('No correlation plots shown: The number of non-NaN or constant columns ({}) is less than 2'.format(df.shape[1]))
        return
    corr = df.corr()
    plt.figure(num=None, figsize=(graphWidth, graphWidth), dpi=80, facecolor='w', edgecolor='k')
    corrMat = plt.matshow(corr, fignum = 1)
    plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)
    plt.yticks(range(len(corr.columns)), corr.columns)
    plt.gca().xaxis.tick_bottom()
    plt.colorbar(corrMat)
    plt.title('Correlation Matrix for {}'.format(filename), fontsize=15)
    plt.show()
    
# Scatter and density plots
def plotScatterMatrix(df, plotSize, textSize):
    df = df.select_dtypes(include =[np.number]) # keep only numerical columns
    # Remove rows and columns that would lead to df being singular
    df = df.dropna('columns')
    df = df[[col for col in df if df[col].nunique() > 1]] # keep columns where there are more than 1 unique values
    columnNames = list(df)
    if len(columnNames) > 10: # reduce the number of columns for matrix inversion of kernel density plots
        columnNames = columnNames[:10]
    df = df[columnNames]
    ax = pd.plotting.scatter_matrix(df, alpha=0.75, figsize=[plotSize, plotSize], diagonal='kde')
    corrs = df.corr().values
    for i, j in zip(*plt.np.triu_indices_from(ax, k = 1)):
        ax[i, j].annotate('Corr. coef = %.3f' % corrs[i, j], (0.8, 0.2), xycoords='axes fraction', ha='center', va='center', size=textSize)
    plt.suptitle('Scatter and Density Plot')
    plt.show()

plotPerColumnDistribution(dataset_norm1, 10, 5)

plotCorrelationMatrix(dataset_norm1, 15)

"""* In addition to the code, summarize most relevant literature or efforts to analyze the same dataset you have picked.

<b >The creators of the dataset are researchers at the Electronics and Telecommunications Research Institute in South Korea.</b>

* <b><i style="color:red">Time-Series Aware Precision and Recall for Anomaly Detection</i> by {Hyeok-Ki Shin, Woomyo Lee, Jeong-Han Yun, HyoungChun Kim} - The publication made by the researchers who created the dataset highlights a methodology "for evaluating anomaly detection methods in time-series data" (Shin).</b>
<br>

* <b><i style="color:red">Implementation of Programmable CPS Testbed for Anomaly Detection</i> by {Hyeok-Ki Shin, Woomyo Lee, Jeong-Han Yun, HyoungChun Kim} - In this publication, the researchers outline their approach for collecting data from the CPS testbed.</b>
<br>

* <b><i style="color:red">[TaPR Project](https://github.com/saurf4ng/TaPR)</i> by {Hyeok-Ki Shin, Woomyo Lee, Jeong-Han Yun, HyoungChun Kim} - this Github repository houses a Python file that can be used to evaluate anomaly detection methods. This was also provided by the original researchers.</b>

<b>Besides the resources shown above, there were not many resources available to explain the best approach for analyzing the ICS dataset using a time-series aware approach.</b>

* If you have a new dataset with no or limited Kernel, survey literature not necessary on any work on this dataset in particular, but in the domain of the dataset (as you may have many other similar or relevant datasets)


* <b><i style="color:red">Deep Learning for Time Series Forecasting</i> by {Jason Brownlee} - This book details various applications of deep learning to time series data. The book covers convolutional neural networks, LSTMs, SARIMA, as well as various approaches for human activity recognition. </b>
<br>

* <b><i style="color:red">Long Short-Term Memory Networks with Python</i> by {Jason Brownlee} - This book details various implementations that can be tested when using Long Short-Term Memory networks to solve data science problems against sequenced data. The author justifies that the Long Short-Term Memory, or LSTM, network is a type of Recurrent Neural Network" that is "designed for sequence problems" (Brownlee). According to Jason Brownlee, Long Short-Term Memory networks are useful for sequence prediction problems, sequence classification problems, sequence generation problems, and sequence-to-sequence prediction. A sequence prediction problem - as defined by Jason Brownlee - is a problem where the model attempts to "predict elements of a sequence on the basis of preceding elements" (Brownlee). In other words, this includes weather forecasting and stock market prediction. On the other hand, a sequence classification problem is a problem where the model is built to predict "a class label for a given input sequence" (Brownlee). Examples of sequence classification problems include DNA sequence classification, anomaly detection, and sentiment analysis. This text helped justify LSTM as the neural network to use to solve the sequence classification problem.</b>
<br>

* <b><i style="color:red">LSTM Fully Convolutional Networks for Time Series Classification</i> by {Fazle Karim, Somshubra Majumdar, Houshang Darabi, Shun Chen} - This IEEE publication by Karim, Majumdar, Darabi, and Chen highlights how convolutional neural networks can be combined with LSTM for significantly improved performance. I have not modified the LSTM to support a convolutional network, however this publication will be useful if and when an attempt is made to further improve performance.</b>

<h3>Section 2 - Latest Code, EDA, Feature Engineering</h3>

<b>From this we can see that this is a time series dataset with a column for binary classification. Either the industrial control system is under attack or not under attack. The normal dataset has 0s for all cells in the attack column since it is not under attack. The abnormal dataset has 1s in cells for the timesteps during which the system is under attack.</b>
"""

col_atk = pd.DataFrame(dataset_norm1, columns = ['time', 'P1.B4022', 'P1.FCV03D', 'attack'])
col_atk

"""<b>From this we can see how P1.B4022, P1.FCV03D, and P1.FCV03Z behave over time under normal operating conditions.</b>"""

fig, ax = plt.subplots(figsize=(14, 6), dpi=80)
ax.plot_date(dataset_norm1['time'], dataset_norm1['P1.B4022'].astype(float), label='P1.B4022', color='red', linewidth=.5)
ax.plot_date(dataset_norm1['time'], dataset_norm1['P1.FCV03D'].astype(float), label='P1.FCV03D', color='green', linewidth=.5)
ax.plot_date(dataset_norm1['time'], dataset_norm1['P1.FCV03Z'].astype(float), label='P1.FCV03Z', color='blue', linewidth=.5)
plt.legend(loc='lower left')
ax.set_title('P1 Boiler Process Sensor Data - Normal Conditions (3)', fontsize=16)
plt.savefig('p1_norm.png')
plt.show()

"""<b>From this we can see how P1.B4022, P1.FCV03D, and P1.FCV03Z behave over time under abnormal operating conditions.</b><b style="color:red"> This shows that there are significant anomalies in the behavior of these data points when the system is under attack.</b>"""

fig2, ax2 = plt.subplots(figsize=(14, 6), dpi=80)
ax2.plot_date(dataset_abnorm1['time'], dataset_abnorm1['P1.B4022'].astype(float), label='P1.B4022', color='red', linewidth=.5)
ax2.plot_date(dataset_abnorm1['time'], dataset_abnorm1['P1.FCV03D'].astype(float), label='P1.FCV03D', color='green', linewidth=.5)
ax2.plot_date(dataset_abnorm1['time'], dataset_abnorm1['P1.FCV03Z'].astype(float), label='P1.FCV03Z', color='blue', linewidth=.5)
plt.legend(loc='lower left')
ax2.set_title('P1 Boiler Process Sensor Data - Abnormal Conditions (3)', fontsize=16)
plt.savefig('p1_abnorm.png')
plt.show()

"""<b>From this we can see how P2.VT01e and P2.VYT03 behave over time under normal operating conditions.</b>"""

fig3, ax3 = plt.subplots(figsize=(28, 12), dpi=80)
ax3.plot_date(dataset_norm1['time'], dataset_norm1['P2.VT01e'].astype(float), label='P2.VT01e', color='green', linewidth=.5)
ax3.plot_date(dataset_norm1['time'], dataset_norm1['P2.VYT03'].astype(float), label='P2.VYT03', color='blue', linewidth=.5)
plt.legend(loc='lower left')
ax3.set_title('P2 Turbine Process Sensor Data - Normal Conditions (2)', fontsize=16)
plt.savefig('p2_norm.png')
plt.show()

"""<b>From this we can see how P2.VT01e and P2.VYT03 behave over time under abnormal operating conditions.</b><b style="color:red"> This shows that there are significant anomalies in the behavior of these data points when the system is under attack.</b>"""

fig4, ax4 = plt.subplots(figsize=(28, 12), dpi=80)
ax4.plot_date(dataset_abnorm1['time'], dataset_abnorm1['P2.VT01e'].astype(float), label='P2.VT01e', color='green', linewidth=.5)
ax4.plot_date(dataset_abnorm1['time'], dataset_abnorm1['P2.VYT03'].astype(float), label='P2.VYT03', color='blue', linewidth=.5)
plt.legend(loc='lower left')
ax4.set_title('P2 Turbine Process Sensor Data - Abnormal Conditions (2)', fontsize=16)
plt.savefig('p2_abnorm.png')
plt.show()

"""<b>From this we can see how P3.LT01 behaves over time under normal operating conditions.</b>"""

fig5, ax5 = plt.subplots(figsize=(28, 12), dpi=80)
ax5.plot_date(dataset_norm1['time'], dataset_norm1['P3.LT01'].astype(float), label='P3.LT01', color='green', linewidth=.5)
plt.legend(loc='lower left')
ax5.set_title('P3 Water-Treatment Process Sensor Data - Normal Conditions (1)', fontsize=16)
plt.savefig('p3_norm.png')
plt.show()

"""<b>From this we can see how P3.LT01 behaves over time under abnormal operating conditions.</b><b style="color:red"> We can see that there is a spike in this sensor when under attack.</b>"""

fig6, ax6 = plt.subplots(figsize=(28, 12), dpi=80)
ax6.plot_date(dataset_abnorm1['time'], dataset_abnorm1['P3.LT01'].astype(float), label='P3.LT01', color='green', linewidth=.5)
plt.legend(loc='lower left')
ax6.set_title('P3 Water-Treatment Process Sensor Data - Abnormal Conditions (1)', fontsize=16)
plt.savefig('p3_abnorm.png')
plt.show()

"""<b>From this we can see how P4.HT_LD, P4.HT_PO, P4.LD, P4.ST_LD, P4.ST_PO behave over time under normal operating conditions.</b>"""

fig7, ax7 = plt.subplots(figsize=(28, 12), dpi=80)
ax7.plot_date(dataset_norm1['time'], dataset_norm1['P4.HT_LD'].astype(float), label='P4.HT_LD', color='purple', linewidth=.5)
ax7.plot_date(dataset_norm1['time'], dataset_norm1['P4.HT_PO'].astype(float), label='P4.HT_PO', color='yellow', linewidth=.5)
ax7.plot_date(dataset_norm1['time'], dataset_norm1['P4.LD'].astype(float), label='P4.LD', color='red', linewidth=.5)
ax7.plot_date(dataset_norm1['time'], dataset_norm1['P4.ST_LD'].astype(float), label='P4.ST_LD', color='green', linewidth=.5)
ax7.plot_date(dataset_norm1['time'], dataset_norm1['P4.ST_PO'].astype(float), label='P4.ST_PO', color='blue', linewidth=.5)
plt.legend(loc='lower left')
ax7.set_title('P4 HIL Sensor Data - Normal Conditions (3)', fontsize=16)
plt.savefig('p4_norm.png')
plt.show()

"""<b>From this we can see how P4.HT_LD, P4.HT_PO, P4.LD, P4.ST_LD, P4.ST_PO behave over time under abnormal operating conditions.</b><b style="color:red"> There isn't a significant change in how these 5 data points behave when the system is under attack. Thus we can conclude that there is need for dimensionality reduction and/or feature selection to remove the features that are not strong predictors of the attack column.</b>"""

fig8, ax8 = plt.subplots(figsize=(28, 12), dpi=80)
ax8.plot_date(dataset_abnorm1['time'], dataset_abnorm1['P4.HT_LD'].astype(float), label='P4.HT_LD', color='purple', linewidth=.5)
ax8.plot_date(dataset_abnorm1['time'], dataset_abnorm1['P4.HT_PO'].astype(float), label='P4.HT_PO', color='yellow', linewidth=.5)
ax8.plot_date(dataset_abnorm1['time'], dataset_abnorm1['P4.LD'].astype(float), label='P4.LD', color='red', linewidth=.5)
ax8.plot_date(dataset_abnorm1['time'], dataset_abnorm1['P4.ST_LD'].astype(float), label='P4.ST_LD', color='green', linewidth=.5)
ax8.plot_date(dataset_abnorm1['time'], dataset_abnorm1['P4.ST_PO'].astype(float), label='P4.ST_PO', color='blue', linewidth=.5)
plt.legend(loc='lower left')
ax8.set_title('P4 HIL Sensor Data - Abnormal Conditions (3)', fontsize=16)
plt.savefig('p4_abnorm.png')
plt.show()

"""<h3>Section 2 (Continued) - Feature Engineering</h3>

* We talked about feature selection methods and I uploaded several samples about that. I expect you for the least to reuse such code towards your dataset 
<b>I applied feature selection techniques to reduce the number of features from 59 to 9 and then applied principal component analysis to project the 9 features onto a 5 dimensional subspace.</b>


* You can use the following questions to guide you in what to include in this section (if you can answer all those questions with evidences/screenshots from your work, that is great) 
<b>The code is shown below.</b>


* What were the most important features?
<b>The 9 most important features selected from the f_classif function were P1.B2004 (Heat-exchanger outlet pressure setpoint), P1.B3004 (Water level setpoint in return water tank), P1.B4002 (Heat-exchanger outlet temperature setpoint), P1.B4022 (Temperature demand to follow P1. B4005 and electrical load from
steam-turbine model), P1.FT01 (Digital value of FT01 flow transmitter), P1.LIT01 (Water level of return water tank), P1.PCV01D (Position command for LCV01 valve), P1.PCV01Z (Current position of PCV01 valve), and P2.SD01 (User speed demand). Chi2 was not used because there are negative values that are important to the dataset.</b>


* We suggest you provide: a variable importance plot (an example here about halfway down the page), showing the 10-20 most important features and partial plots for the 3-5 most important features


* If this is not possible, you should provide a list of the most important features. How did you select features?
<b>The f_classif function was used with the SelectKBest() function. Chi2 was not used because there are negative values that are important to the dataset.</b>


* Did you make any important feature transformations?
<b>I applied feature scaling using the StandardScaler() function.</b>


* Did you use external data? (if permitted)
<b>No.</b>

Many customers are happy to trade off model performance for simplicity. With this in mind:
* Is there a subset of features that would get 90-95% of your final performance? Which features? <b>I was able to get 93% accuracy using a combination of feature selection, principal component analysis, and then passing the 5 principal components as input to the neural network.</b>


* What model that was most important?
<b>Both the simple LSTM and LSTM autoencoder models produced 93% accuracy for classifying the time series data as not under attack or under attack. They both produced similar results when run with enough epochs.</b>


* What would the simplified model score? <b>Both models scored a 93% accuracy.</b>

Try and restrict your simple model to fewer than 10 features and one training method. <b>9 features were selected and then principal component analysis was applied to project the 9 features onto a 5 dimensional subspace.</b>
"""

# 09/11/2019 - 11/01/2019
# 11/01/2019 - 11/05/2019
combined = pd.concat([dataset_norm1, dataset_abnorm1, dataset_norm2, dataset_abnorm2])
combined.sort_values(by=['time'])

# X = P1, P2, P3, P4 Sensor Data
X = combined.iloc[:, 1:60].values

# Y = Attack Column
Y = combined.iloc[:, [61]].values

# Feature Selection
X_new = SelectKBest(f_classif, k=9).fit_transform(X,Y)

# Split
X_train, X_test, Y_train, Y_test = train_test_split(X_new, Y, test_size=0.25, random_state=0)

# Feature Scaling
sc = StandardScaler()
X_train = sc.fit_transform(X_train)
X_test = sc.transform(X_test)

# Reduce Dimensionality using PCA
pca = PCA(n_components=5)
X_train = pca.fit_transform(X_train)
X_test = pca.transform(X_test)
explained_variance = pca.explained_variance_ratio_
print('Explained Variance: ', explained_variance)

X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])
X_test = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])

"""<h3>Section 3 - Training Methods</h3>

* Use the questions below to guide your effort in this section. (if you can answer all those questions with evidences/screenshots from your work, that is great)


* What training methods did you use? <b>I tried two training methods, one was a simple LSTM model architecture and the other was a autoencoder LSTM architecture.</b>


* Did you ensemble the models? <b>No.</b>


* If you did ensemble, how did you weight the different models? A6. Interesting findings <b>I did not use ensemble methods.</b>


* What was the most important trick you used? <b>Installing CUDA and using my graphics card for parallel processing instead of using my CPU to train the model. I was able to gain a significant improvement in training time by installing and setting up CUDA and using the CuDNNLSTM() function instead of using the LSTM() function. However, I left the LSTM() code in both functions as well.</b>


* What do you think set you apart from others in the competition? <b>The original researchers at ETRI did not outline a specific approach and I did not see any other approaches. However, the original researchers did outline an approach for evaluating models called time-series aware precision and recall for anomaly detection using pure Python in their code. The approach that I have tried utilizes preprocessing functions from scikit-kit learn and LSTM from tensorflow which is well-suited for solving time-series classification problems.</b>


* Did you find any interesting relationships in the data that don't fit in the sections above? <b>I did not find any interesting relationships that did not fit in the sections above.</b>
"""

def autoencoder_model(X):
    inputs = Input(shape=(X.shape[1], X.shape[2]))

    # CPU - Comment out GPU lines and uncomment these lines to use CPU
    # L1 = LSTM(16, activation='relu', return_sequences=True, kernel_regularizer=regularizers.l2(0.00))(inputs)
    # L2 = LSTM(4, activation='relu', return_sequences=False)(L1)
    # L3 = RepeatVector(X.shape[1])(L2)
    # L4 = LSTM(4, activation='relu', return_sequences=True)(L3)
    # L5 = LSTM(16, activation='relu', return_sequences=True)(L4)
    # L6 = LSTM(1, activation='sigmoid', return_sequences=True)(L5)

    # GPU (must have CUDA enabled NVIDIA card, CUDA installed, and tensorflow-gpu must be installed)
    L1 = CuDNNLSTM(16, return_sequences=True, kernel_regularizer=regularizers.l2(0.00))(inputs)
    L2 = CuDNNLSTM(4, return_sequences=False)(L1)
    L3 = RepeatVector(X.shape[1])(L2)
    L4 = CuDNNLSTM(4, return_sequences=True)(L3)
    L5 = CuDNNLSTM(16, return_sequences=True)(L4)
    L6 = CuDNNLSTM(1, return_sequences=True)(L5)

    output = TimeDistributed(Dense(X.shape[2]))(L6)
    model = Model(inputs=inputs, outputs=output)
    return model

def simple_lstm(X):
    model = Sequential()
    
    # CPU - Comment out GPU lines and uncomment these lines to use CPU
    # model.add(LSTM(10, input_shape=(X.shape[1], X.shape[2])))
    
    # GPU (must have CUDA enabled NVIDIA card, CUDA installed, and tensorflow-gpu must be installed)
    model.add(CuDNNLSTM(10, input_shape=(X.shape[1], X.shape[2])))
    
    model.add(Dropout(0.2))
    model.add(Dense(1, activation='sigmoid'))
    return model

"""<h4>Section 3.1 - Simple LSTM Training with Dropout</h3>"""

opt = SGD(lr=0.0001)
model = simple_lstm(X_train)
model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

nb_epochs = 30
batch_size = 128
history = model.fit(X_train, Y_train.ravel(), epochs=nb_epochs, batch_size=batch_size,validation_split=0.05, initial_epoch=1, use_multiprocessing=False).history
scores = model.evaluate(X_test, Y_test, verbose=1)
print("Accuracy: %.2f%%" % (scores[1]*100))

"""<h4>Section 3.2 - LSTM Autoencoder Training</h3>"""

opt = SGD(lr=0.0001)
model = autoencoder_model(X_train)
model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])
model.summary()

nb_epochs = 30
batch_size = 128
history = model.fit(X_train, Y_train.ravel(), epochs=nb_epochs, batch_size=batch_size,validation_split=0.05, initial_epoch=1, use_multiprocessing=False).history
scores = model.evaluate(X_test, Y_test, verbose=1)
print("Accuracy: %.2f%%" % (scores[1]*100))

# plot training losses
fig10, ax10 = plt.subplots(figsize=(14, 6), dpi=80)
ax10.plot(history['loss'], 'b', label='Train', linewidth=2)
ax10.plot(history['val_loss'], 'r', label='Validation', linewidth=2)
ax10.set_title('Model loss', fontsize=16)
ax10.set_ylabel('Loss (Binary Cross Entropy)')
ax10.set_xlabel('Epoch')
ax10.legend(loc='upper right')
plt.show()

# X_pred = model.predict(X_test)
# X_pred = X_pred.reshape(X_pred.shape[0], X_pred.shape[2])
# X_pred = pd.DataFrame(X_pred, columns=test.columns)
# X_pred.index = test.index

# scored = pd.DataFrame(index=test.index)
# Xtest = X_test.reshape(X_test.shape[0], X_test.shape[2])
# scored['Loss_mae'] = np.mean(np.abs(X_pred-Xtest), axis = 1)
# scored['Threshold'] = 0.3
# scored['Anomaly'] = scored['Loss_Binary_Cross_Entropy'] > scored['Threshold']
# scored.head()

"""<h3>Section 4 - Conclusion and Future State</h3>

I will continue to build my understanding of LSTM and neural networks and look to verify my approach and improve/tune the model.
"""

